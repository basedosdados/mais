
# Igual ao dataset.name mas como lower case.
# Exemplos: br_ibge_populacao, br_inep_censo_escolar
dataset_id: br_mec_prouni

table_id: dicionario

# Título da tabela.
title: Dicionário

# Descreva a tabela. Essas são as primeiras frases que um usuário vai ver.
# Você não precisa ser muito conciso. Sinta-se a vontade para dar exemplos de
# como usar os dados.
# Se souber, liste também aplicações: pesquisa, apps, etc. que usem os dados.,
description: Dicionário para a base do ProUni

# As máximas unidades espaciais que a tabela cobre.
# Exemplo:
#   - sa.br
spatial_coverage:

# Anos cobertos pela tabela.
# Preencher como lista de intervalos.
# Exemplos: ['1995(1)2019'], ['2002(2)2010', '2016', '2020'].
temporal_coverage:

# A unidade temporal com qual a tabela é atualizada.
# Opções em 'https://basedosdados.org/api/3/action/bd_available_options'
update_frequency: unique

# Nível de observação da tabela: o que representa cada linha.
observation_level:

last_updated:
    metadata: '2022-09-05'
    data: '2022-09-05 16:30:15'
    release: '2022-09-05 16:30:16'

# Versão da tabela. Seguindo o padrão de semantic versioning.
# Exemplo: v1.1.3
version: v1.0

# Quem está preenchendo esses metadados?
published_by:
    name: Lucas Moreira
    email: lucas.moreira@basedosdados.org
    github_user: 
    ckan_user:
    website:

# Qual organização/departamento/pessoa tratou os dados?
# As vezes há um ponto intermediário entre os dados originais e subir na Base dos Dados.
# Se essa pessoa é você, preencha abaixo com suas informações.
data_cleaned_by:
    name: Lucas Passos Barreto
    email: lucaspassosbarreto@hotmail.com
    github_user: oterrab
    ckan_user:
    website:

# Se houve passos de tratamento, limpeza e manipulação de dados, descreva-os aqui.
data_cleaning_description: Criação de dicionário baseado nas strings dos dados originais

# Url do código de limpeza dos dados.
data_cleaning_code_url: https://github.com/basedosdados/mais/tree/master/bases/br_mec_prouni/code/microdados

# Organização que ajudou institucionalmente na disponibilização dos dados.
partner_organization:
    name:
    organization_id:

# Url dos dados originais no GCP Storage.
raw_files_url:

# Url dos arquivos auxiliares no GCP Storage.
auxiliary_files_url:

# Url da tabela de arquitetura no GCP Storage.
architecture_url:

source_bucket_name: basedosdados-dev

project_id_prod: basedosdados-dev

project_id_staging: basedosdados-dev

# Liste as colunas da tabela que representam partições.
# Não esqueça de deletar essas colunas nas tabelas .csv na hora de subir para o BigQuery.
# Isso poupará muito tempo e dinheiro às pessoas utilizando essa tabela.
# Se não houver partições, não modifique abaixo.
partitions:

# Quais são as colunas? Certifique-se de escrever uma boa descrição, as pessoas vão gostar
# para saber sobre o que é a coluna.
# Adicionar todas as colunas manualmente pode ser bastante cansativo, por isso, quando
# inicializando este arquivo de configuração, você pode apontar a função para uma amostra de dados que
# preencherá automaticamente as colunas.
# Algumas colunas existirão apenas na tabela final, você as construirá em `publish.sql`.
# Para esses, defina is_in_staging como False.
# Além disso, você deve adicionar as colunas de partição aqui e definir is_partition como True.
columns:
    - name: id_tabela
      bigquery_type: string
      description: ID da tabela
      temporal_coverage:
      covered_by_dictionary:
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data: no
      is_in_staging: True
      is_partition: False
    - name: nome_coluna
      bigquery_type: string
      description: Nome da coluna
      temporal_coverage:
      covered_by_dictionary:
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data: no
      is_in_staging: True
      is_partition: False
    - name: chave
      bigquery_type: string
      description: Chave
      temporal_coverage:
      covered_by_dictionary:
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data: no
      is_in_staging: True
      is_partition: False
    - name: cobertura_temporal
      bigquery_type: string
      description: Cobertura temporal
      temporal_coverage:
      covered_by_dictionary:
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data: no
      is_in_staging: True
      is_partition: False
    - name: valor
      bigquery_type: string
      description: Valor
      temporal_coverage:
      covered_by_dictionary:
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data: no
      is_in_staging: True
      is_partition: False

number_rows: 20

metadata_modified:


dataset_id: test_dataset

table_id: test_table

# Descreva a tabela. Essas são as primeiras frases que um usuário vai ver.
# Você não precisa ser muito conciso. Sinta-se a vontade para dar exemplos de
# como usar os dados.
# Se souber, liste também aplicações: pesquisa, apps, etc. que usem os dados.,
description: table-approve passou por aqui v1.0 -> teste com retries 

# A máxima unidade espacial que a tabela cobre.
spatial_coverage:

# Anos cobertos pela tabela.
# Preencher como lista de intervalos.
# Exemplo: 1995(1)2019.
temporal_coverage:

# A unidade temporal com qual a tabela é atualizada.
# Opções em 'https://basedosdados.org/api/3/action/bd_available_options'
update_frequency:

# Entidade representada por cada linha.
# Opções em 'https://basedosdados.org/api/3/action/bd_available_options'
entity:

# A unidade temporal representada por cada linha.
# Opções em 'https://basedosdados.org/api/3/action/bd_available_options'
time_unit:

# O conjunto mínimo de colunas identificando cada linha unicamente.
# Preencha com os nomes de colunas.
# Exemplos: id_municipio, ano.
# Pode ser vazio pois certas tabelas não possuem identificadores.
identifying_columns:
    - ano
    - sigla_uf

last_updated:
    metadata:
    data:
    release:

# Versão da tabela. Seguindo o padrão de semantic versioning.
# Exemplo: v1.1.3
version:

# Quem está preenchendo esses metadados?
published_by:
    name:
    email:
    github_user:
    website:
    ckan_user:

# Qual organização/departamento/pessoa tratou os dados?
# As vezes há um ponto intermediário entre os dados originais e subir na Base dos Dados.
# Se essa pessoa é você, preencha abaixo com suas informações.
data_cleaned_by:
    name:
    email:
    github_user:
    ckan_user:
    website:
    code_url:

# Se houve passos de tratamento, limpeza e manipulação de dados, descreva-os aqui.
data_cleaning_description:

# Url dos dados originais no GCP Storage.
raw_files_url:

# Url dos arquivos auxiliares no GCP Storage.
auxiliary_files_url:

# Url da tabela de arquitetura no GCP Storage.
architecture_url:

# A tabela tem colunas que precisam de dicionário?
# Opções: yes, no.
covered_by_dictionary:

source_bucket_name: basedosdados-dev

project_id_prod: basedosdados-dev

project_id_staging: basedosdados-dev

# Liste as colunas da tabela que representam partições.
# Não esqueça de deletar essas colunas nas tabelas .csv na hora de subir para o BigQuery.
# Isso poupará muito tempo e dinheiro às pessoas utilizando essa tabela.
# Se não houver partições, não modifique abaixo.
partitions: ano, sigla_uf, mes

bdm_file_size:

# Quais são as colunas? Certifique-se de escrever uma boa descrição, as pessoas vão gostar
# para saber sobre o que é a coluna.
# Adicionar todas as colunas manualmente pode ser bastante cansativo, por isso, quando
# inicializando este arquivo de configuração, você pode apontar a função para uma amostra de dados que
# preencherá automaticamente as colunas.
# Algumas colunas existirão apenas na tabela final, você as construirá em `publish.sql`.
# Para esses, defina is_in_staging como False.
# Além disso, você deve adicionar as colunas de partição aqui e definir is_partition como True.
columns:
    - name: ano
      bigquery_type:
      description: testenado table-approve
      temporal_coverage:
      covered_by_dictionary:
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data:
      is_in_staging:
      is_partition: true
    - name: sigla_uf
      bigquery_type:
      description: testenado testando table-approve
      temporal_coverage:
      covered_by_dictionary:
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data:
      is_in_staging:
      is_partition: true
    - name: mes
      bigquery_type:
      description:
      temporal_coverage:
      covered_by_dictionary:
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data:
      is_in_staging:
      is_partition: true
    - name: dado
      bigquery_type:
      description:
      temporal_coverage:
      covered_by_dictionary:
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data:
      is_in_staging:
      is_partition:

metadata_modified: 

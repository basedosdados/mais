{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import basedosdados as bd\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import glob\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disclamer -> é importante verificar se as versões do chrome e do webdriver são compatíves.\n",
    "folder_location = 'br_me_empresas_exportadoras_importadoras/input'\n",
    "driver_path = 'C:/webdrivers/chromedriver.exe'\n",
    "folder_donwload = r\"br_me_empresas_exportadoras_importadoras\\input\"\n",
    "\n",
    "def baixar_tabelas_exportacao_importacao(url: str) -> pd:\n",
    "    options = Options()\n",
    "    options.add_experimental_option(\"prefs\", \n",
    "    {\"download.default_directory\": folder_donwload})\n",
    "    navegador = webdriver.Chrome(executable_path = driver_path, options = options)\n",
    "    navegador.get(url)\n",
    "    #atencao ##\n",
    "    #precisa ser o tempo necessario para carregar a página e baixar a tabela \n",
    "    tm.sleep(20)\n",
    "\n",
    "#inserir o ano corrente para atualizar\n",
    "for year in range(1997,2022):\n",
    "    url1 = f'https://balanca.economia.gov.br/balanca/outras/EMPRESAS_CADASTRO_{year}.xlsx' \n",
    "    baixar_tabelas_exportacao_importacao(url1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_location = 'br_me_empresas_exportadoras_importadoras/input'\n",
    "filenames = glob.glob(folder_location + \"/*.xlsx\")\n",
    "\n",
    "lista_empresas = []\n",
    "\n",
    "##checar de fato se cada ano pra imp e exp tem so um registro de cnpj\n",
    "for file in filenames: \n",
    "    #ler folhas de um mesmo ano\n",
    "\n",
    "    #data é a folha com empresas exportadoras\n",
    "    #data1 é a folha com importadoras\n",
    "    data = pd.read_excel(file, sheet_name = 0, skiprows = 7, dtype=str)\n",
    "    data1 = pd.read_excel(file, sheet_name = 1, skiprows = 7, dtype=str)\n",
    "    \n",
    "    #dava erro de Length of values (1) does not match length of index (15293)\n",
    "    #o que nao ocorre se o argumento passado é uma string.\n",
    "    \n",
    "    data1['id_exportacao_importacao_tmp'] = '1'\n",
    "    data['id_exportacao_importacao_tmp'] = '0'\n",
    "\n",
    "    df_empresas = pd.concat([data1, data])\n",
    "    \n",
    "    #nas tabelas originais, não existe a coluna ano\n",
    "    #optei por adicionar uma coluna com o ano que consta no nome do arquivo no momento da leitura de cada planilha\n",
    "    ano = re.findall(r'\\d+', file)\n",
    "    df_empresas['ano'] = ano[0]\n",
    "    \n",
    "    #criar a variavel id_exportacao_importacao que contara com 3 entradas:\n",
    "    #0 -> empresas exportadoras no ano de referencia\n",
    "    #1 -> empresas importadoras no ano de referencia\n",
    "    #2 -> empresas exportadoras e importadoras no ano de referencia\n",
    "    df_empresas['id_exportacao_importacao'] = np.where(df_empresas['CNPJ'].duplicated(keep=False),\n",
    "    '2', df_empresas['id_exportacao_importacao_tmp'])\n",
    "    #dropar a coluna temporaria ('id_exportacao_importacao_tmp') e dar unique para tirar as repeticoes \n",
    "    df_empresas = df_empresas.drop(columns={'id_exportacao_importacao_tmp'})\n",
    "    df_empresas = df_empresas.drop_duplicates() \n",
    "    \n",
    "    lista_empresas.append(df_empresas)\n",
    "    \n",
    "df_empresas = pd.concat(lista_empresas)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baixar diretorio de municipios da bd\n",
    "df = bd.read_table(dataset_id='br_bd_diretorios_brasil',\n",
    "table_id='municipio',\n",
    "billing_project_id=\"inserir-projeto\")\n",
    "\n",
    "df_cnae2 = bd.read_table(dataset_id='br_bd_diretorios_brasil',\n",
    "table_id='cnae_2',\n",
    "billing_project_id=\"inserir-projeto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renomear variaveis\n",
    "df_empresas = df_empresas.rename(columns = {'CNPJ': 'cnpj',\n",
    "    'EMPRESA' : 'razao_social',\n",
    "    'ENDEREÇO' : 'endereco',\n",
    "    'NÚMERO' : 'numero',\n",
    "    'BAIRRO' : 'bairro',\n",
    "    'CEP' : 'cep',\n",
    "    'MUNICÍPIO' : 'nome',\n",
    "    'UF' : 'sigla_uf',\n",
    "    'CNAE PRIMÁRIA' : 'cnae_2_primaria',\n",
    "    'NATUREZA JURÍDICA' : 'natureza_juridica',\n",
    "    'ano' : 'ano',\n",
    "    'id_exportacao_importacao' : 'id_exportacao_importacao'\n",
    "    })\n",
    "\n",
    "#fazer alteracoes manuais nos nomes de municipios preenchidos errados na base\n",
    "#transformar ambos nomes de municipios em caixa baixa e retirar acentos\n",
    "df['nome'] = df['nome'].str.lower()\n",
    "df['nome'] = df['nome'].str.strip()\n",
    "df_empresas['nome'] = df_empresas['nome'].str.lower()\n",
    "df_empresas['nome'] = df_empresas['nome'].str.strip()\n",
    "\n",
    "#Remover acentos\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])\n",
    "\n",
    "df['nome'] = df['nome'].apply(remove_accents)\n",
    "\n",
    "\n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'embu', 'embu das artes' , df_empresas['nome'])\n",
    "#apesar de existirem 2 municipios que iniciam com o nome 'embu' \n",
    "#o municipio de 'embu-guaçu' possui somente um cep \t06900-000.\n",
    "#nenhuma empresa tem esse cep registrado, logo todas estao em embu das artes\n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'belem de sao francisco' ,'belem do sao francisco' , df_empresas['nome'])\n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'mogi mirin', 'mogi mirim' , df_empresas['nome'])\n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'santana do livramento' ,  \"sant'ana do livramento\" , df_empresas['nome'])\n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'brasopolis',  'brazopolis' , df_empresas['nome'])\n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'picarras' ,  'balneario picarras' , df_empresas['nome'])\n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'lagoa do itaenga' ,'lagoa de itaenga' , df_empresas['nome'])\n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'couto de magalhaes' ,   'couto magalhaes' , df_empresas['nome'])\n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'parati', 'paraty' , df_empresas['nome'])\n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'eldorado dos carajas' ,  'eldorado do carajas' , df_empresas['nome'])\n",
    "df_empresas['nome'] = np.where(df_empresas['nome']== 'sao valerio da natividade' , 'sao valerio' , df_empresas['nome'])\n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'presidente juscelino'  , 'serra caiada' , df_empresas['nome'])      #erro de prenchimento no cadastro  \n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'serido'  ,'sao vicente do serido' , df_empresas['nome']) \n",
    "df_empresas['nome'] = np.where(df_empresas['nome'] == 'mogi-mirim'  ,'mogi mirim' , df_empresas['nome']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazer o merge com os municipios para pegar o id_municipio\n",
    "df_empresas = pd.merge(df_empresas,\n",
    "df[['nome', 'sigla_uf', 'id_municipio']],\n",
    "on = ['nome', 'sigla_uf'],\n",
    "how = 'left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitar as variaveis que não foram normalizadas na base original\n",
    "df_empresas[['id_natureza_juridica', 'natureza_juridica_descricao']] = df_empresas.natureza_juridica.str.split(\"-\", expand=True, n = 1)\n",
    "df_empresas[['cnae_2_primaria', 'cnae_2_primaria_descricao']] = df_empresas.cnae_2_primaria.str.split(\"-\", expand=True, n = 1)\n",
    "df_empresas['cnae_2_primaria'] = df_empresas['cnae_2_primaria'].str.replace(' ', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tirar pontos e numeros da coluna cnae_2 do diretorio da BD.\n",
    "#retirar os 4 primeiros digitos e dar merge \n",
    "\n",
    "df_cnae2['cnae_2_tmp'] = df_cnae2['cnae_2'].str.replace('-','')\n",
    "df_cnae2['cnae_2_tmp'] = df_cnae2['cnae_2_tmp'].str.replace('.','')\n",
    "df_cnae2['cnae_2_tmp'] = df_cnae2['cnae_2_tmp'].str.slice(0, 4)\n",
    "\n",
    "df_empresas = pd.merge(df_empresas,\n",
    "df_cnae2[['cnae_2', 'cnae_2_tmp', 'descricao']],\n",
    "left_on = 'cnae_2_primaria',\n",
    "right_on = 'cnae_2_tmp',\n",
    "how = 'left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empresas = df_empresas.drop(columns=['natureza_juridica_descricao', 'cnae_2_primaria_descricao',\n",
    "'cnae_2_primaria', 'descricao', 'cnae_2_tmp'])\n",
    "\n",
    "df_empresas = df_empresas.rename(columns = {'cnae_2' : 'cnae_2_primaria'})\n",
    "\n",
    "#ordernar colunas de acordo com a tabela de arquitetura\n",
    "df_empresas = df_empresas.loc[:, [\"ano\",\"cnpj\",\"razao_social\",\"id_exportacao_importacao\",\"cnae_2_primaria\", \"id_natureza_juridica\", \"sigla_uf\", \"id_municipio\", \"cep\", \"bairro\",\"endereco\", \"numero\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvar df final particionado por ano\n",
    "anos = df_empresas['ano'].unique()\n",
    "for ano in anos:\n",
    "    #criar diretorio com ano\n",
    "    os.mkdir(f'br_me_empresas_exportadoras_importadoras/output/ano={ano}')\n",
    "    #filtrar ano, dropar coluna ano e salvar\n",
    "    df_empresas.query(f\"ano == {ano}\").drop(columns =['ano']).to_csv(f'C:/Users/gabri/OneDrive/vida_profissional/Projetos/base_dos_dados/br_me_empresas_exportadoras_importadoras/output/ano={ano}/estabelecimentos.csv', \n",
    "    sep = ',', index = False, na_rep= ' ', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criar dicionairo com id_exportacao_importacao\n",
    "#atualizar cobertura temporal em atualizacoes da base\n",
    "dados =  { 'id_tabela' : 'empresas_exportadoras_importadoras', 'nome_coluna' : 'id_exportacao_importacao',  \n",
    "'chave': ['0', '1', '2'], 'cobertura_temporal' : '1997(1)2021' , 'valor' : ['exportou', 'importou', 'exportou e importou'] }\n",
    "\n",
    "dicionario = pd.DataFrame(data=dados)\n",
    "#salvar dic\n",
    "dicionario.to_csv('br_me_empresas_exportadoras_importadoras/extra/dicionario.csv', \n",
    "sep = ',', index = False, na_rep= ' ', encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('vm_basedosdados')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ade41dcf762c71d72b1b092a7170e73699337fb08ef4b88b76f437787b62d91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


# Igual ao dataset.name mas como lower case.
# Exemplos: br_ibge_populacao, br_inep_censo_escolar
dataset_id: br_mapbiomas_estatisticas

table_id: transicao_uf_de_para_quinquenal

# Título da tabela.
title:

# Descreva a tabela. Essas são as primeiras frases que um usuário vai ver.
# Você não precisa ser muito conciso. Sinta-se a vontade para dar exemplos de
# como usar os dados.
# Se souber, liste também aplicações: pesquisa, apps, etc. que usem os dados.,
description:

# As máximas unidades espaciais que a tabela cobre.
# Exemplo:
#   - sa.br
spatial_coverage:

# Anos cobertos pela tabela.
# Preencher como lista de intervalos.
# Exemplos: ['1995(1)2019'], ['2002(2)2010', '2016', '2020'].
temporal_coverage:
    - 1990(5)2020

# A unidade temporal com qual a tabela é atualizada.
# Opções em 'https://basedosdados.org/api/3/action/bd_available_options'
update_frequency: five_years

# Nível de observação da tabela: o que representa cada linha.
observation_level:
    - country: br
      entity: state
      columns:
          - sigla_uf
    - columns:
          - id_classe_de
    - columns:
          - id_classe_para
    - entity: year
      columns:
          - ano

last_updated:
    metadata:
    data:
    release:

# Versão da tabela. Seguindo o padrão de semantic versioning.
# Exemplo: v1.1.3
version: v1.1

# Quem está preenchendo esses metadados?
published_by:
    name: Ricardo Dahis
    email: rdahis@basedosdados.org
    github_user: rdahis
    ckan_user: rdahis
    website: www.ricardodahis.com

# Qual organização/departamento/pessoa tratou os dados?
# As vezes há um ponto intermediário entre os dados originais e subir na Base dos Dados.
# Se essa pessoa é você, preencha abaixo com suas informações.
data_cleaned_by:
    name: Ricardo Dahis
    email: rdahis@basedosdados.org
    github_user: rdahis
    ckan_user: rdahis
    website: www.ricardodahis.com

# Se houve passos de tratamento, limpeza e manipulação de dados, descreva-os aqui.
data_cleaning_description:

# Url do código de limpeza dos dados.
data_cleaning_code_url:

# Organização que ajudou institucionalmente na disponibilização dos dados.
partner_organization:
    name:
    organization_id:

# Url dos dados originais no GCP Storage.
raw_files_url:

# Url dos arquivos auxiliares no GCP Storage.
auxiliary_files_url:

# Url da tabela de arquitetura no GCP Storage.
architecture_url:

source_bucket_name: basedosdados-dev

project_id_prod: basedosdados-dev

project_id_staging: basedosdados-dev

# Liste as colunas da tabela que representam partições.
# Não esqueça de deletar essas colunas nas tabelas .csv na hora de subir para o BigQuery.
# Isso poupará muito tempo e dinheiro às pessoas utilizando essa tabela.
# Se não houver partições, não modifique abaixo.
partitions:
    - ano

# Quais são as colunas? Certifique-se de escrever uma boa descrição, as pessoas vão gostar
# para saber sobre o que é a coluna.
# Adicionar todas as colunas manualmente pode ser bastante cansativo, por isso, quando
# inicializando este arquivo de configuração, você pode apontar a função para uma amostra de dados que
# preencherá automaticamente as colunas.
# Algumas colunas existirão apenas na tabela final, você as construirá em `publish.sql`.
# Para esses, defina is_in_staging como False.
# Além disso, você deve adicionar as colunas de partição aqui e definir is_partition como True.
columns:
    - name: ano
      bigquery_type: int64
      description: Ano
      temporal_coverage:
        - (1)
      covered_by_dictionary: no
      directory_column:
          dataset_id: br_bd_diretorios_data_tempo
          table_id: ano
          column_name: ano
      measurement_unit: year
      has_sensitive_data: no
      observations:
      is_in_staging: true
      is_partition: true
    - name: sigla_uf
      bigquery_type: string
      description: Sigla da unidade da federação
      temporal_coverage:
        - (1)
      covered_by_dictionary: no
      directory_column:
          dataset_id: br_bd_diretorios_brasil
          table_id: uf
          column_name: sigla
      measurement_unit:
      has_sensitive_data: no
      observations:
      is_in_staging: true
      is_partition: false
    - name: id_classe_de
      bigquery_type: string
      description: ID Classe - De
      temporal_coverage:
        - (1)
      covered_by_dictionary: no
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data: no
      observations:
      is_in_staging: true
      is_partition: false
    - name: id_classe_para
      bigquery_type: string
      description: ID Classe - Para
      temporal_coverage:
        - (1)
      covered_by_dictionary: no
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit:
      has_sensitive_data: no
      observations:
      is_in_staging: true
      is_partition: false
    - name: area
      bigquery_type: float64
      description: Área
      temporal_coverage:
      covered_by_dictionary: no
      directory_column:
          dataset_id:
          table_id:
          column_name:
      measurement_unit: km^2
      has_sensitive_data: no
      observations:
      is_in_staging: true
      is_partition: false

number_rows:

metadata_modified: '2022-11-21T22:05:53.972942'

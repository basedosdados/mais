
# Suba dados na BD+

## Por que minha organiza√ß√£o deve subir dados na BD+?

- **Capacidade de cruzar suas bases com dados de diferentes
  organiza√ß√µes** de forma simples e f√°cil. J√° s√£o centenas de conjuntos
  dados p√∫blicos das maiores organiza√ß√µes do Brasil e do mundo presentes
  no nossod *datalake*.

- **Compromisso com a transpar√™ncia, qualidade dos dados e
  desenvolvimento de melhores pesquisas, an√°lises e solu√ß√µes** para a
  sociedade. N√£o s√≥ democratizamos o acesso a dados abertos, mas dados
  de qualidade. Temos um time especializado que revisa e garante a qualidade dos
  dados adicionados ao *datalake*.

- **Participa√ß√£o de uma comunidade que cresce cada vez mais**: milhares
  de jornalistas, pesquisadores(as), desenvolvedores(as), j√° utilizam e
  acompanham a Base dos Dados.
  <!-- TODO: Colocar aqui o link do nosso painel de audiencia quando tiver pronto :) -->

## Passo a passo para subir dados

Quer subir dados na BD+ e nos ajudar a construir esse reposit√≥rio?
*Maravilha!* Organizamos tudo o que voc√™ precisa no manual abaixo, em
menos de 10 passos.

Para facilitar a explica√ß√£o, vamos seguir um exemplo j√° pronto com dados da [RAIS](https://basedosdados.org/dataset/br-me-rais).

!!! Tip "Voc√™ pode navegar pelas etapas no menu √† esquerda."
    Sugerimos fortemente que entre em nosso [canal no
    Discord](https://discord.gg/huKWpsVYx4) para tirar d√∫vidas e
    interagir com a equipe e outros(as) colaboradores(as)! üòâ

### Antes de come√ßar

Alguns conhecimentos s√£o necess√°rias para realizar esse processo:

- **Python, R, SQL e/ou Stata**, para criar os c√≥digos de captura e limpeza dos dados.
- **Linha de comando**, para configurar seu ambiente local
  e conex√£o com o Google Cloud.
- **Github**, para subir seu c√≥digo para revis√£o da
  nossa equipe.

!!! Tip "N√£o tem alguma dessas habilidades mas quer colaborar?"
    Temos um time de dados que pode te ajudar, basta entrar no [nosso
    Discord](https://discord.gg/huKWpsVYx4) e mandar uma mensagem em #quero-contribuir.

### 1. Informar seu interesse para a gente

Mantemos a lista de conjuntos que ainda n√£o est√£o na BD+ no nosso [Github](https://github.com/basedosdados/mais/issues?q=is%3Aopen+is%3Aissue+label%3Adata+label%3Aenhancement). Para come√ßar a subir uma base do seu interesse, basta abrir um [novo issue](https://github.com/basedosdados/mais/issues/new?assignees=&labels=data&template=br_novos_dados.md&title=%5Bdados%5D+%3Cdataset_id%3E) de dados e preencher as informa√ß√µes indicadas por l√°.

!!! Info "Caso sua base (conjunto) j√° esteja listada, basta marcar seu usu√°rio do Github como `assignee`."

### 2. Baixar nossa pasta _template_ para dados

[Baixe aqui a pasta
_template_](https://drive.google.com/drive/folders/1xXXon0vdjSKr8RCNcymRdOKgq64iqfS5?usp=sharing)
e renomeie para o nome do seu conjunto de dados, `<dataset_id>`
([veja aqui como nomear seu conjunto](../style_data)). Ela facilita todos os
passos daqui pra frente. Sua
estrutura √© a seguinte:

- `<dataset_id>/`
    - `code/`: C√≥digos necess√°rios √† **captura** e **limpeza** dos dados
    ([vejo no passo
    4](#4-escrever-codigo-de-captura-e-limpeza-de-dados)).
    - `input/`: Cont√©m todos os arquivos com dados originais, exatamente
    como baixados da fonte prim√°ria **Esses arquivos n√£o devem ser
    modificados.**
    - `output/`: Arquivos finais, j√° no formato pronto para subir na BD+.
    - `tmp/`: Quaisquer arquivos tempor√°rios criados pelo c√≥digo em `/code` no processo de limpeza e tratamento.
    - `extra/`
        - `architecture/`: Tabelas de arquitetura ([veja no passo 3](#3-preencher-as-tabelas-de-arquitetura)).
        - `auxiliary_files/`: Arquivos auxiliares aos dados ([veja no passo 5](#5-caso-necessario-organizar-arquivos-auxiliares)).
        - `dicionario.csv`: Tabela dicion√°rio de todo o conjunto de dados ([veja no passo
          6](#6-caso-necessario-criar-tabela-dicionario)).

### 3. Preencher as tabelas de arquitetura

As tabelas de arquitetura determinam **qual a estrutura de
cada tabela do seu conjunto de dados**. Elas definem, por exemplo, o nome, ordem e metadados das colunas, e
como uma coluna deve ser tratada quando h√° mudan√ßas em vers√µes (por
exemplo, e uma coluna muda de nome de um ano para o outro).

!!! Info "Cada tabela do conjunto de dados deve ter sua pr√≥pria tabela de arquitetura (planilha), que pode ser preenchida no Google Drive ou localmente (Excel, editor de texto)."

<!-- 
TODO: N√£o vejo rela√ß√£o dessas perguntas com o exemplo dado
da tabela de arquitetura da RAIS.
Perguntas que uma arquitetura deve responder:
* *Quais ser√£o as tabelas finais na base?* Essas n√£o precisam ser
  exatamente o que veio nos dados brutos. -> n√£o tem isso no exemplo
* *Qual √© n√≠vel da observa√ß√£o de cada tabela?* O "n√≠vel da observa√ß√£o" √©
  a menor unidade a que se refere cada linha na tabela (ex: municipio-ano, candidato,
  estabelecimento-cnae). -> n√£o tem isso no exemplo
* *Ser√° gerada alguma tabela derivada com agrega√ß√µes em cima dos dados
  originais?* -> n√£o tem isso no exemplo -->

#### Exemplo: RAIS - Tabelas de arquitetura

As tabelas de arquitetura preenchidas [podem ser consultadas aqui](https://drive.google.com/drive/folders/1OtsucP_KhiUEJI6F6k_cagvXfwZCFZF2?usp=sharing). Seguindo nosso [manual de estilo](../style_data), n√≥s renomeamos, definimos o tipo, preenchemos descri√ß√µes, indicamos se h√° dicion√°rio ou diret√≥rio, preenchemos campos (e.g. cobertura temporal e unidade de medida) e fizemos a compatibiliza√ß√£o entre anos para todas as vari√°veis (colunas).

Nas tabelas desse conjunto existiam colunas que deixaram de existir em
determinados anos. Por isso, foi necess√°rio compatibilizar:
criamos colunas √† direita chamadas `nome_original_YYYY`, em ordem descendente (e.g. 2022,
2021, 2020, ...). Nessas colunas inclu√≠mos _todas_ as vari√°veis de cada
ano.

Para as que foram exclu√≠das da vers√£o em produ√ß√£o,
deixamos seu nome como `(deletado)` e n√£o preenchemos nenhum metadado.
Por exemplo, a coluna `Municipio` da tabela `microdados_vinculos` n√£o
foi adicionada pois por padr√£o usamos somente o c√≥digo IBGE para
identificar munic√≠pios (seu nome fica numa tabela de
[Diret√≥rios](../style_data/#diretorios)). Logo, ela aparece com o nome
`(deletado)` na respectiva tabela de arquitetura (pen√∫ltima linha).

!!! Tip "Quando terminar de preencher as tabelas de arquitetura, entre em contato com a equipe da Base dos Dados ou nossa comunidade para validar tudo. √â importante ter certeza que est√° fazendo sentido _antes_ de come√ßar a escrever c√≥digo."

### 4. Escrever c√≥digo de captura e limpeza de dados

Ap√≥s validadas as tabelas de arquitetura, podemos escrever os c√≥digos de
**captura** e **limpeza** dos dados.

- **Captura**: C√≥dido que baixa automaticamente todos os dados originais e os salva em `/input`. Esses dados podem estar dispon√≠veis em portais ou links FTP, podem ser raspados de sites, entre outros.

- **Limpeza**: C√≥digo que transforma os dados originais salvos em `/input` nos dados limpos prontos para serem subidos na BD+ salvos em `/output`, tudo baseado nas tabelas de arquitetura.

Cada tabela limpa para produ√ß√£o pode ser salva como um arquivo `.csv` √∫nico ou, caso seja muito grande (e.g. acima de 100-200 mb), ser particionada no formato [Hive](https://cloud.google.com/bigquery/docs/hive-partitioned-loads-gcs) em v√°rios sub-arquivos `.csv`. Nossa recomenda√ß√£o √© particionar tabelas por `ano`, `mes`, `sigla_uf`, ou no m√°ximo por `id_municipio`.

!!! Tip "No pacote `basedosdados` voc√™ encontra fun√ß√µes √∫teis para limpeza dos dados"
    Definimos fun√ß√µes para particionar tabelas de forma autom√°tica,
    criar vari√°veis comuns (e.g. `sigla_uf` a partir de `id_uf`) e
    outras. Veja em [Python](../api_reference_python) e [R](../api_reference_r)

#### Padr√µes necess√°rios no c√≥digo

- Devem ser escritos em [Python](https://www.python.org/),
  [R](https://www.r-project.org/), ou [Stata](https://www.stata.com/) -
  para que a revis√£o possa ser realizada pela equipe.
- Pode estar em script (`.py`, `.r`, ...) ou *notebooks* (Google Colab, Jupyter, Rmarkdown, etc).
- Os caminhos de arquivos devem ser atalhos _relativos_ √† pasta ra√≠z
  (`<dataset_id>`), ou seja, n√£o devem depender dos caminhos do seu
  computador.
- A limpeza deve seguir nosso [manual de estilo](../style_data) e as [melhores pr√°ticas de programa√ß√£o](https://en.wikipedia.org/wiki/Best_coding_practices).

#### Exemplo: RAIS - C√≥digo de limpeza

O c√≥digo de limpeza foi constru√≠do em Stata e [pode ser consultado
aqui](https://github.com/basedosdados/mais/tree/master/bases/br_me_rais/code).

A tabela `microdados_vinculos` da RAIS √© uma tabela muito grande
(+250GB) por isso n√≥s particionamos por `ano` e `sigla_uf`. O
particionamento foi feito usando a estrutura de pastas
`/microdados_vinculos/ano=YYYY/sigla_uf=XX`.

### 5. (Caso necess√°rio) Organizar arquivos auxiliares

√â comum bases de dados serem distribu√≠das com arquivos auxiliares. Esses podem incluir notas t√©cnicas, descri√ß√µes de coleta e amostragem, etc. Para ajudar usu√°rios da Base dos Dados terem mais contexto e entenderem melhor os dados, organize todos esses arquivos auxiliares em `/extra/auxiliary_files`.

Fique √† vontade para estruturar sub-pastas como quiser l√° dentro. O que importa √© que fique claro o que s√£o esses arquivos.

### 6. (Caso necess√°rio) Criar tabela dicion√°rio

Muitas vezes, especialmente com bases antigas, h√° m√∫ltiplos dicion√°rios
em formatos Excel ou outros. Na Base dos Dados n√≥s unificamos tudo em um
√∫nico arquivo em formato `.csv` - um √∫nico dicion√°rio para todas as
colunas de todas as tabelas do seu conjunto.

!!! Info "Detalhes importantes de como construir seu dicion√°rio est√£o no nosso [manual de estilo](../style_data/#dicionarios)."

#### Exemplo: RAIS - Dicion√°rio

O dicion√°rio completo [pode ser consultado
aqui](https://docs.google.com/spreadsheets/d/12Wwp48ZJVux26rCotx43lzdWmVL54JinsNnLIV3jnyM/edit?usp=sharing).
Ele j√° possui a estrutura padr√£o que utilizamos para dicion√°rios.

### 7. Subir tudo no Google Cloud

Tudo pronto! Agora s√≥ falta subir para o Google Cloud e enviar para
revis√£o. Para isso, vamos usar o cliente `basedosdados` (dispon√≠vel em
linha de comando e Python) que facilita as configura√ß√µes e etapas do processo.

#### Configure seu projeto no Google Cloud e um _bucket_ no Google Storage

Os dados v√£o passar ao todo por 3 lugares no Google Cloud:

1. **Storage**: local onde ser√£o armazenados o arquivos "frios" (arquiteturas, dados, arquivos auxiliares).
2. **BigQuery**: super banco de dados do Google, dividido em 2 projetos/tipos de tabela:
    - *Staging*: banco para teste e tratamento final do conjunto de dados
    - *Produ√ß√£o*: banco oficial de publica√ß√£o dos dados (nosso projeto `basedosdados`! ou o seu mesmo caso queira reproduzir o ambiente)

√â necess√°rio ter uma conta Google e um projeto (gratuito) no Google
Cloud. Para criar seu projeto basta:

1. Acessar o [link](https://console.cloud.google.com/projectselector2/home/dashboard) e aceitar o Termo de Servi√ßos do Google Cloud.
2. Clicar em `Create Project/Criar Projeto` - escolha um nome bacana para o seu projeto, ele ter√° tamb√©m um `Project ID` que ser√° utilizado para configura√ß√£o local.
3. Depois de criado o projeto, v√° at√© a funcionalidade de
   [Storage](https://console.cloud.google.com/storage) e crie uma pasta
   (_bucket_) para subir os dados (pode ter o mesmo nome do projeto).

#### Configure suas credenciais localmente e prepare o ambiente

No seu terminal:

1. Instale nosso cliente: `pip install basedosdados`.
2. Rode `basedosdados config init` e siga o passo a passo para configurar localmente com as credenciais de seu projeto no Google Cloud.

> Caso seu ambiente de produ√ß√£o n√£o permita o uso interativo do nosso cliente ou apresente alguma outra dificuldade relativa a esse modo de configura√ß√£o, voc√™ pode configurar o `basedosdados` a partir de vari√°veis de ambiente da seguinte forma:
>
>```bash
> export BASEDOSDADOS_CONFIG=$(cat ~/.basedosdados/config.toml | base64)
> export BASEDOSDADOS_CREDENTIALS_PROD=$(cat ~/.basedosdados/credentials/prod.json | base64)
> export BASEDOSDADOS_CREDENTIALS_STAGING=$(cat ~/.basedosdados/credentials/staging.json | base64)
>```
>
3. Clone um _fork_ do nosso [reposit√≥rio](https://github.com/basedosdados/mais) localmente.
4. D√™ um `cd` para a pasta local do reposit√≥rio e abra uma nova branch
   com `git checkout -b [BRANCH_ID]`. Todas as adi√ß√µes e modifica√ß√µes
   ser√£o feitas nessa _branch_.

#### Suba e configure uma tabela no seu _bucket_

Aqui s√£o dois passos: primeiro publicamos uma base (conjunto) e depois publicamos tabelas.

Para publicar uma **base (conjunto)**:

1. Crie a pasta do conjunto no *bucket* rodando:

    ```bash
    basedosdados dataset create [DATASET_ID]
    ```

2. Preencha os arquivos de configura√ß√£o criados em `<dataset_id>/`:
    - `README.md`: informa√ß√µes √∫teis para quem for ver o c√≥digo no Github.
    - `dataset_config.yaml`: informa√ß√µes espec√≠ficas do conjunto (j√° vem
      com um modelo para preenchimento).
3. Atualize as informa√ß√µes preenchidas do conjunto com:

    ```bash
    basedosdados dataset update [DATASET_ID]
    ```

Para publicar uma **tabela (ou v√°rias!)**:

1. Crie a tabela no *bucket*, indicando o caminho do arquivo no seu local, rodando:

    ```bash
    basedosdados table create [DATASET_ID] [TABLE_ID] --path '/[DATASET_ID]/output/[TABLE_ID]'.
    ```

2. Preencha os arquivos de configura√ß√£o da tabela:

- `/[TABLE_ID]/table_config.yaml`: informa√ß√µes espec√≠ficas da tabela.
- `/[TABLE_ID]/publish.sql`: aqui voc√™ pode indicar tratamentos finais
    na tabela `staging` em SQL para publica√ß√£o (ex: modificar a query para
    dar um JOIN em outra tabela da BD+ e selecionar vari√°veis).

3. Publique a tabela em produ√ß√£o:

    ```bash
    basedosdados table publish [DATASET_ID] [TABLE_ID]
    ```

Consulte tamb√©m nossa [API](../api_reference_cli) para mais detalhes de cada m√©todo.

!!! Tip "Abra o console do BigQuery e rode algumas _queries_ para testar se foi tudo publicado corretamente. Estamos desenvolvendo testes autom√°ticos para facilitar esse processo no futuro."

### 8. Validar e publicar metadados

Para publicar os metadados preenchidos nos arquivos `dataset_config.yaml` e `table_config.yaml`, o processo √© simples.

1. Coloque suas credenciais do CKAN no arquivo
   `~/.basedosdados/config.toml`, preenchendo os campos `api_key` e
   `url` em `[ckan]`. Este arquivo √© criado automaticamente ao rodar
   `basedosdados config init` [(veja no passo
   7)](#7-subir-tudo-no-google-cloud).

2. (Recomendado) Valide os metadados do conjunto atrav√©s do comando `basedosdados metadata validate [DATASET_ID]`. Para validar metadados de tabelas, basta rodar `basedosdados metadata validate [DATASET_ID] [TABLE_ID]`.

3. Publique os metadados do conjunto j√° preenchidos e validados com
   `basedosdados metadata publish [DATASET_ID]`. Para publicar metadados
   de tabelas, use `basedosdados metadata publish [DATASET_ID]
   [TABLE_ID]`.

> Para publicar metadados de ambos (conjunto e tabela), use
> `basedosdados metadata publish [DATASET_ID] [TABLE_ID] --all=True`.

#### Atualizando metadados de bases ou tabelas j√° existentes

Atrav√©s do m√≥dulo `metadata` √© poss√≠vel tamb√©m trabalhar com bases e tabelas j√° existentes na plataforma. Elas podem ser atualizadas a partir do procedimento que descrevemos a seguir.

1. Rode `basedosdados metadata create [DATASET_ID]` para puxar os
   metadados do conjunto dispon√≠veis no site para o arquivo
   `dataset_config.yaml`. Para puxar metadados de tabelas, use
   `basedosdados metadata create [DATASET_ID] [TABLE_ID]`, que ir√°
   atualizo arquivo `table_config.yaml`
2. Preencha os novos valores de metadados nos respectivos arquivos.
3. Rode `basedosdados metadata validate [DATASET_ID]` e para publicar os
   metadados atualizados do conjutno use `basedosdados metadata publish [DATASET_ID]`. O mesmo pode ser feito
   para tabela adicionando o parametro `[TABLE_ID]`

### 9. Enviar tudo para revis√£o

Ufa, √© isso! Agora s√≥ resta enviar tudo para revis√£o no
[reposit√≥rio](https://github.com/basedosdados/mais) da Base dos Dados.
Crie os _commits_ necess√°rios e rode `git push origin [BRANCH_ID]`.
Depois √© s√≥ abrir um _pull request_ (PR) no nosso reposit√≥rio.

**E agora?** Nossa equipe ir√° revisar os dados e metadados submetidos
via Github. Podemos entrar em contato para tirar d√∫vidas ou solicitar
mudan√ßas no c√≥digo. Quando tudo estiver OK, fazemos um _merge_ do seu
*pull request*, e os dados s√£o automaticamente publicados na nossa
plataforma!
